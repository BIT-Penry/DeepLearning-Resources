{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d29e766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch  # pyright: ignore[reportMissingImports]\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.is_tensor(torch.randn(2, 3)))\n",
    "print(torch.cuda.is_available()) # 因为mac的m4芯片没有cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0b6cc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS 可用: True\n",
      "MPS 已构建: True\n",
      "使用设备: mps\n",
      "tensor([[ 0.8576, -0.1156, -0.2067],\n",
      "        [-0.4358, -0.1326,  0.7850],\n",
      "        [-2.2826,  0.1363, -0.8187]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch  # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# 检查 MPS 是否可用\n",
    "print(f\"MPS 可用: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS 已构建: {torch.backends.mps.is_built()}\")\n",
    "\n",
    "# 如果可用，使用 MPS 设备\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"使用设备: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"使用设备: {device}\")\n",
    "\n",
    "# 创建张量并移动到 MPS 设备\n",
    "x = torch.randn(3, 3).to(device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98871555",
   "metadata": {},
   "source": [
    "# MPS (Metal Performance Shaders) 详细介绍\n",
    "\n",
    "## 什么是 MPS？\n",
    "\n",
    "**MPS (Metal Performance Shaders)** 是 Apple 为 macOS 和 iOS 系统提供的 GPU 加速框架。它是 Apple Silicon（M1/M2/M3/M4 等芯片）和部分 Intel Mac 上使用 Metal 图形 API 进行高性能计算的接口。\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "1. **Metal**：Apple 的低级图形和计算 API，类似于 NVIDIA 的 CUDA 或 AMD 的 OpenCL\n",
    "2. **MPS Backend**：PyTorch 通过 MPS backend 让开发者可以在 Apple Silicon 上使用 GPU 加速深度学习计算\n",
    "3. **统一内存架构**：Apple Silicon 的 CPU 和 GPU 共享内存，减少了数据传输开销\n",
    "\n",
    "### MPS vs CUDA\n",
    "\n",
    "| 特性 | MPS | CUDA |\n",
    "|------|-----|------|\n",
    "| 平台 | Apple Silicon (M系列芯片) | NVIDIA GPU |\n",
    "| 内存架构 | 统一内存（CPU/GPU共享） | 独立显存 |\n",
    "| 数据传输 | 几乎零开销 | 需要显式传输 |\n",
    "| 生态系统 | 相对较新，支持的操作较少 | 成熟，支持所有操作 |\n",
    "| 性能 | 针对 Apple 硬件优化 | 针对 NVIDIA 硬件优化 |\n",
    "\n",
    "### MPS 的优势\n",
    "\n",
    "✅ **零拷贝**：统一内存架构意味着数据在 CPU 和 GPU 之间传输几乎不需要额外开销  \n",
    "✅ **能效比高**：Apple Silicon 的能效比优秀，适合长时间训练  \n",
    "✅ **原生支持**：macOS 系统级支持，无需额外驱动  \n",
    "\n",
    "### MPS 的限制\n",
    "\n",
    "⚠️ **操作支持**：不是所有 PyTorch 操作都支持 MPS（但核心操作都已支持）  \n",
    "⚠️ **性能**：对于某些操作，可能不如 NVIDIA GPU 快  \n",
    "⚠️ **仅限 Apple 设备**：只能在 Mac 上使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ca2274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MPS 状态检查\n",
      "==================================================\n",
      "PyTorch 版本: 2.9.0\n",
      "MPS 已构建: True\n",
      "MPS 已构建: True\n",
      "\n",
      "==================================================\n",
      "设备选择\n",
      "==================================================\n",
      "✅ 使用 MPS 设备: mps\n",
      "\n",
      "==================================================\n",
      "张量操作示例\n",
      "==================================================\n",
      "张量 x 形状: torch.Size([1000, 1000]), 设备: mps:0\n",
      "张量 y 形状: torch.Size([1000, 1000]), 设备: mps:0\n",
      "矩阵乘法结果形状: torch.Size([1000, 1000]), 设备: mps:0\n",
      "\n",
      "==================================================\n",
      "神经网络层示例\n",
      "==================================================\n",
      "线性层输出形状: torch.Size([1000, 500]), 设备: mps:0\n"
     ]
    }
   ],
   "source": [
    "# MPS 详细使用示例\n",
    "\n",
    "import torch  # pyright: ignore[reportMissingImports]\n",
    "import time\n",
    "\n",
    "# 1. 检查 MPS 是否可用\n",
    "print(\"=\" * 50)\n",
    "print(\"MPS 状态检查\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"MPS 已构建: {torch.backends.mps.is_available()}\")\n",
    "print(f\"MPS 已构建: {torch.backends.mps.is_built()}\")\n",
    "\n",
    "# 2. 设备选择策略\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"设备选择\")\n",
    "print(\"=\" * 50)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"✅ 使用 MPS 设备: {device}\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"✅ 使用 CUDA 设备: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"⚠️  使用 CPU 设备: {device}\")\n",
    "\n",
    "# 3. 创建张量并移动到设备\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"张量操作示例\")\n",
    "print(\"=\" * 50)\n",
    "x = torch.randn(1000, 1000, device=device)\n",
    "y = torch.randn(1000, 1000, device=device)\n",
    "print(f\"张量 x 形状: {x.shape}, 设备: {x.device}\")\n",
    "print(f\"张量 y 形状: {y.shape}, 设备: {y.device}\")\n",
    "\n",
    "# 4. 矩阵运算\n",
    "z = torch.matmul(x, y)\n",
    "print(f\"矩阵乘法结果形状: {z.shape}, 设备: {z.device}\")\n",
    "\n",
    "# 5. 神经网络层示例\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"神经网络层示例\")\n",
    "print(\"=\" * 50)\n",
    "linear = torch.nn.Linear(1000, 500).to(device)\n",
    "output = linear(x)\n",
    "print(f\"线性层输出形状: {output.shape}, 设备: {output.device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e8c13f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "性能对比测试 (矩阵乘法)\n",
      "==================================================\n",
      "矩阵大小: 2000 x 2000\n",
      "迭代次数: 10\n",
      "\n",
      "MPS 时间: 0.0613 秒\n",
      "CPU 时间: 0.1041 秒\n",
      "加速比: 1.70x\n",
      "✅ MPS 比 CPU 快 1.70 倍\n"
     ]
    }
   ],
   "source": [
    "# MPS vs CPU 性能对比\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device_mps = torch.device(\"mps\")\n",
    "    device_cpu = torch.device(\"cpu\")\n",
    "    \n",
    "    # 测试矩阵乘法性能\n",
    "    size = 2000\n",
    "    iterations = 10\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"性能对比测试 (矩阵乘法)\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"矩阵大小: {size} x {size}\")\n",
    "    print(f\"迭代次数: {iterations}\")\n",
    "    \n",
    "    # MPS 测试\n",
    "    x_mps = torch.randn(size, size, device=device_mps)\n",
    "    y_mps = torch.randn(size, size, device=device_mps)\n",
    "    \n",
    "    # 预热（MPS 第一次运行可能较慢）\n",
    "    _ = torch.matmul(x_mps, y_mps)\n",
    "    torch.mps.synchronize()  # 等待 MPS 操作完成\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        z_mps = torch.matmul(x_mps, y_mps)\n",
    "    torch.mps.synchronize()\n",
    "    mps_time = time.time() - start_time\n",
    "    \n",
    "    # CPU 测试\n",
    "    x_cpu = torch.randn(size, size, device=device_cpu)\n",
    "    y_cpu = torch.randn(size, size, device=device_cpu)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for _ in range(iterations):\n",
    "        z_cpu = torch.matmul(x_cpu, y_cpu)\n",
    "    cpu_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nMPS 时间: {mps_time:.4f} 秒\")\n",
    "    print(f\"CPU 时间: {cpu_time:.4f} 秒\")\n",
    "    print(f\"加速比: {cpu_time / mps_time:.2f}x\")\n",
    "    \n",
    "    if mps_time < cpu_time:\n",
    "        print(f\"✅ MPS 比 CPU 快 {cpu_time / mps_time:.2f} 倍\")\n",
    "    else:\n",
    "        print(f\"⚠️  CPU 更快（可能因为矩阵较小或 MPS 开销）\")\n",
    "else:\n",
    "    print(\"MPS 不可用，无法进行性能对比\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abfb0aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "MPS 使用注意事项\n",
      "==================================================\n",
      "\n",
      "1. 操作支持检查\n",
      "✅ 基本操作（矩阵乘法）: 支持\n",
      "✅ 激活函数（ReLU）: 支持\n",
      "✅ 卷积操作: 支持\n",
      "\n",
      "2. 数据类型支持\n",
      "✅ float32: 支持\n",
      "✅ float16: 支持（部分操作）\n",
      "⚠️  int64: 某些操作可能不支持，会回退到 CPU\n",
      "\n",
      "3. 内存管理\n",
      "✅ 统一内存架构，无需手动管理 GPU 内存\n",
      "✅ 但大模型仍需注意内存使用\n",
      "\n",
      "4. 同步操作\n",
      "✅ 使用 torch.mps.synchronize() 确保操作完成\n",
      "\n",
      "5. 常见问题处理\n",
      "⚠️  如果某个操作不支持 MPS，PyTorch 会自动回退到 CPU\n",
      "⚠️  某些操作（如某些索引操作）可能不支持，需要先转到 CPU\n",
      "✅ 建议：先测试你的模型，确认所有操作都支持 MPS\n"
     ]
    }
   ],
   "source": [
    "# MPS 使用注意事项和最佳实践\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MPS 使用注意事项\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    \n",
    "    # 1. 检查操作是否支持 MPS\n",
    "    print(\"\\n1. 操作支持检查\")\n",
    "    x = torch.randn(5, 5, device=device)\n",
    "    print(f\"✅ 基本操作（矩阵乘法）: 支持\")\n",
    "    print(f\"✅ 激活函数（ReLU）: 支持\")\n",
    "    print(f\"✅ 卷积操作: 支持\")\n",
    "    \n",
    "    # 2. 数据类型支持\n",
    "    print(\"\\n2. 数据类型支持\")\n",
    "    print(f\"✅ float32: 支持\")\n",
    "    print(f\"✅ float16: 支持（部分操作）\")\n",
    "    print(f\"⚠️  int64: 某些操作可能不支持，会回退到 CPU\")\n",
    "    \n",
    "    # 3. 内存管理\n",
    "    print(\"\\n3. 内存管理\")\n",
    "    print(\"✅ 统一内存架构，无需手动管理 GPU 内存\")\n",
    "    print(\"✅ 但大模型仍需注意内存使用\")\n",
    "    \n",
    "    # 4. 同步操作\n",
    "    print(\"\\n4. 同步操作\")\n",
    "    x = torch.randn(100, 100, device=device)\n",
    "    y = torch.matmul(x, x)\n",
    "    torch.mps.synchronize()  # 确保所有 MPS 操作完成\n",
    "    print(\"✅ 使用 torch.mps.synchronize() 确保操作完成\")\n",
    "    \n",
    "    # 5. 常见问题处理\n",
    "    print(\"\\n5. 常见问题处理\")\n",
    "    print(\"⚠️  如果某个操作不支持 MPS，PyTorch 会自动回退到 CPU\")\n",
    "    print(\"⚠️  某些操作（如某些索引操作）可能不支持，需要先转到 CPU\")\n",
    "    print(\"✅ 建议：先测试你的模型，确认所有操作都支持 MPS\")\n",
    "    \n",
    "else:\n",
    "    print(\"MPS 不可用\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce42b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: mps\n",
      "\n",
      "模型已移动到: mps\n",
      "\n",
      "开始训练...\n",
      "损失值: 2.3328\n",
      "输出形状: torch.Size([32, 10])\n",
      "✅ 训练完成！所有操作都在 mps 上执行\n"
     ]
    }
   ],
   "source": [
    "# 完整的神经网络训练示例（使用 MPS）\n",
    "\n",
    "import torch  # pyright: ignore[reportMissingImports]\n",
    "import torch.nn as nn  # pyright: ignore[reportMissingImports]\n",
    "import torch.optim as optim  # pyright: ignore[reportMissingImports]\n",
    "\n",
    "# 检查设备\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 定义简单的神经网络\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # 展平\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# 创建模型并移动到设备\n",
    "model = SimpleNet().to(device)\n",
    "print(f\"\\n模型已移动到: {device}\")\n",
    "\n",
    "# 创建示例数据\n",
    "batch_size = 32\n",
    "x = torch.randn(batch_size, 28, 28, device=device)\n",
    "y = torch.randint(0, 10, (batch_size,), device=device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练一个批次\n",
    "print(\"\\n开始训练...\")\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "output = model(x)\n",
    "loss = criterion(output, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f\"损失值: {loss.item():.4f}\")\n",
    "print(f\"输出形状: {output.shape}\")\n",
    "print(f\"✅ 训练完成！所有操作都在 {device} 上执行\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972a2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
